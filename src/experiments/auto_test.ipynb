{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fd950a5",
   "metadata": {},
   "source": [
    "# Evaluación Automatizada del Chatbot Turístico\n",
    "\n",
    "Este notebook ejecuta automáticamente una serie de preguntas predefinidas a través del chatbot y guarda las respuestas para su análisis posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77606a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Configurar el path para encontrar los módulos\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "src_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.insert(0, src_dir)\n",
    "print(f\"Directorio src agregado al path: {src_dir}\")\n",
    "\n",
    "# Cargar variables de entorno\n",
    "env_path = os.path.join(os.path.dirname(src_dir), '.env')\n",
    "load_dotenv(env_path)\n",
    "print(f\"Archivo .env cargado desde: {env_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2561bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar la configuración del entorno\n",
    "def check_environment():\n",
    "    checks = {\n",
    "        \"Python Path\": src_dir in sys.path,\n",
    "        \"Módulo agents\": False,\n",
    "        \"Módulo chatbot\": False,\n",
    "        \"Módulo vector_db\": False,\n",
    "        \".env file\": os.path.exists(env_path),\n",
    "        \"questions.csv\": os.path.exists('questions.csv')\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        import agents\n",
    "        checks[\"Módulo agents\"] = True\n",
    "    except ImportError as e:\n",
    "        print(f\"Error importando agents: {e}\")\n",
    "        \n",
    "    try:\n",
    "        import chatbot\n",
    "        checks[\"Módulo chatbot\"] = True\n",
    "    except ImportError as e:\n",
    "        print(f\"Error importando chatbot: {e}\")\n",
    "        \n",
    "    try:\n",
    "        import vector_db\n",
    "        checks[\"Módulo vector_db\"] = True\n",
    "    except ImportError as e:\n",
    "        print(f\"Error importando vector_db: {e}\")\n",
    "    \n",
    "    print(\"\\n=== Verificación del Entorno ===\")\n",
    "    all_passed = True\n",
    "    for check, passed in checks.items():\n",
    "        status = \"✓\" if passed else \"✗\"\n",
    "        if not passed:\n",
    "            all_passed = False\n",
    "        print(f\"{status} {check}\")\n",
    "    \n",
    "    if not all_passed:\n",
    "        print(\"\\n⚠ Hay problemas en la configuración que deben ser resueltos\")\n",
    "    else:\n",
    "        print(\"\\n✓ Todo está correctamente configurado\")\n",
    "    \n",
    "    return all_passed\n",
    "\n",
    "# Ejecutar verificación\n",
    "environment_ok = check_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b624859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el chatbot y sus componentes\n",
    "from agents.agent_manager import AgentManager\n",
    "from chatbot.core import CubaChatbot\n",
    "from vector_db.chroma_storage import VectorStorage\n",
    "from chatbot.core import CubaChatbot\n",
    "from chatbot.gap_detector import GapDetector\n",
    "from crawlers.dynamic_crawler import DynamicCrawler\n",
    "from agents.retriever_agent import RetrieverAgent\n",
    "from agents.generator_agent import GeneratorAgent\n",
    "from agents.gap_detector_agent import GapDetectorAgent\n",
    "from agents.updater_agent import UpdaterAgent\n",
    "from agents.agent_manager import AgentManager\n",
    "from agents.guide_agent import GuideAgent\n",
    "from agents.planner_agent import TravelPlannerAgent\n",
    "\n",
    "# Inicializar el chatbot\n",
    "def initialize_chatbot():\n",
    "    try:\n",
    "        print(\"\\nInicializando Chatbot...\")\n",
    "        chatbot = CubaChatbot()\n",
    "        print(\"Chatbot inicializado correctamente\")\n",
    "        \n",
    "        return chatbot\n",
    "    except ImportError as e:\n",
    "        print(f\"\\nError de importación: {str(e)}\")\n",
    "        print(\"Verifica que:\")\n",
    "        print(\"1. Estás en el directorio correcto\")\n",
    "        print(\"2. El directorio 'src' está en el Python path\")\n",
    "        print(f\"3. Los módulos están disponibles en: {src_dir}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError inesperado: {str(e)}\")\n",
    "        print(f\"Tipo de error: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        print(\"\\nDetalles del error:\")\n",
    "        print(traceback.format_exc())\n",
    "        return None\n",
    "\n",
    "# Inicializar el chatbot\n",
    "print(\"=== Iniciando configuración del chatbot ===\")\n",
    "chatbot = initialize_chatbot()\n",
    "\n",
    "if chatbot is not None:\n",
    "    print(\"\\n✓ Chatbot inicializado exitosamente\")\n",
    "    print(f\"Tipo de chatbot: {type(chatbot).__name__}\")\n",
    "else:\n",
    "    print(\"\\n✗ Error al inicializar el chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea4a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las preguntas desde el archivo CSV\n",
    "def load_questions():\n",
    "    try:\n",
    "        questions_df = pd.read_csv('questions.csv')\n",
    "        return questions_df['pregunta'].tolist()\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar las preguntas: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Cargar las preguntas\n",
    "questions = load_questions()\n",
    "print(f\"Se cargaron {len(questions)} preguntas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a89096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt):\n",
    "    chatbot = CubaChatbot()\n",
    "    if not chatbot.vector_db.get_documents():\n",
    "        print(\"\\nCargando datos iniciales...\\n\")\n",
    "        try:\n",
    "            chatbot.vector_db.reload_data()\n",
    "            if not chatbot.vector_db.get_documents():\n",
    "                print(\"Error: No se pudieron cargar los datos iniciales\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error crítico: {str(e)}\")\n",
    "\n",
    "    detector = GapDetector(chatbot.vector_db)\n",
    "    updater = DynamicCrawler()\n",
    "    guide_agent = GuideAgent(chatbot.vector_db)\n",
    "    planner_agent = TravelPlannerAgent(chatbot.vector_db)\n",
    "\n",
    "    # Inicialización de agentes\n",
    "    retriever_agent = RetrieverAgent(chatbot.vector_db)\n",
    "    generator_agent = GeneratorAgent(guide_agent, planner_agent)\n",
    "    gap_detector_agent = GapDetectorAgent(detector)\n",
    "    updater_agent = UpdaterAgent(updater)\n",
    "\n",
    "    # Inicialización del manager\n",
    "    manager = AgentManager([\n",
    "        retriever_agent,\n",
    "        generator_agent,\n",
    "        gap_detector_agent,\n",
    "        updater_agent\n",
    "    ])\n",
    "\n",
    "    # Procesar input del usuario\n",
    "    # Recuperar contexto (opcional, si lo usas)\n",
    "    retrieval_task = {\"type\": \"retrieve\", \"query\": prompt}\n",
    "    context = manager.dispatch(retrieval_task, {})\n",
    "\n",
    "    # Generar respuesta\n",
    "    generate_task = {\"type\": \"generate\", \"prompt\": prompt}\n",
    "    response = manager.dispatch(generate_task, context)\n",
    "\n",
    "    # Verificar si necesita actualización\n",
    "    detect_task = {\"type\": \"detect_gap\", \"prompt\": prompt, \"response\": response}\n",
    "    needs_update = manager.dispatch(detect_task, context)\n",
    "\n",
    "    if needs_update:\n",
    "        # Identificar fuentes a actualizar\n",
    "        sources = detector.identify_outdated_sources(prompt)\n",
    "        update_task = {\"type\": \"update_sources\", \"sources\": sources}\n",
    "        manager.dispatch(update_task, context)\n",
    "        chatbot.vector_db.reload_data()\n",
    "        # Regenerar respuesta\n",
    "        response = manager.dispatch(generate_task, context)\n",
    "\n",
    "    # Agregar respuesta final\n",
    "    if hasattr(response, \"choices\"):\n",
    "        response_text = \" \".join([choice.message.content for choice in response.choices])\n",
    "    else:\n",
    "        response_text = str(response)\n",
    "\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d076a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para procesar las preguntas y obtener respuestas\n",
    "def process_questions(questions):\n",
    "    results = []\n",
    "    \n",
    "    for i, question in enumerate(questions, 1):\n",
    "        try:\n",
    "            print(f\"\\nProcesando pregunta {i}/{len(questions)}\")\n",
    "            print(f\"Pregunta: {question}\")\n",
    "            \n",
    "            # Obtener respuesta del chatbot\n",
    "            print(\"Enviando pregunta al chatbot...\")\n",
    "            response = generate_response(question)\n",
    "            print(\"Respuesta recibida del chatbot\")\n",
    "            \n",
    "            # Procesar la respuesta según su tipo\n",
    "            if response is None:\n",
    "                raise ValueError(\"La respuesta del chatbot es None\")\n",
    "                \n",
    "            if isinstance(response, dict):\n",
    "                if 'response' in response:\n",
    "                    response_text = response['response']\n",
    "                elif 'message' in response:\n",
    "                    response_text = response['message']\n",
    "                else:\n",
    "                    print(f\"Estructura de respuesta inesperada: {response.keys()}\")\n",
    "                    response_text = str(response)\n",
    "            else:\n",
    "                response_text = str(response)\n",
    "            \n",
    "            print(f\"Longitud de la respuesta: {len(response_text)} caracteres\")\n",
    "            \n",
    "            # Guardar resultado\n",
    "            results.append({\n",
    "                'pregunta': question,\n",
    "                'respuesta_manual': response_text\n",
    "            })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando pregunta {i}: {str(e)}\")\n",
    "            results.append({\n",
    "                'pregunta': question,\n",
    "                'respuesta': f\"ERROR: {str(e)}\",\n",
    "                'id': i\n",
    "            })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620efb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar el experimento\n",
    "if not questions:\n",
    "    print(\"Error: No se pudieron cargar las preguntas\")\n",
    "    print(\"Verifica que:\")\n",
    "    print(\"1. El archivo 'questions.csv' existe en el directorio actual\")\n",
    "    print(\"2. El archivo contiene una columna llamada 'pregunta'\")\n",
    "else:\n",
    "    print(f\"Chatbot inicializado: {type(chatbot).__name__}\")\n",
    "    print(f\"Preguntas cargadas: {len(questions)}\")\n",
    "    print(\"\\nIniciando procesamiento de preguntas...\")\n",
    "    \n",
    "    results = process_questions(questions)\n",
    "    \n",
    "# Guardar resultados finales en JSON\n",
    "results_json = [\n",
    "    {\n",
    "        \"pregunta\": r[\"pregunta\"],\n",
    "        \"respuesta\": r.get(\"respuesta_manual\", \"\")\n",
    "    } \n",
    "    for r in results\n",
    "]\n",
    "\n",
    "with open('responses.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nProceso completado. Resultados guardados en 'responses.json'\")\n",
    "\n",
    "# Mostrar algunas estadísticas\n",
    "print(f\"\\nEstadísticas:\")\n",
    "print(f\"Total de preguntas procesadas: {len(results)}\")\n",
    "print(f\"Preguntas con error: {len([r for r in results if 'ERROR' in str(r.get('respuesta', ''))])}\")\n",
    "\n",
    "# Verificar formato para comparison.ipynb\n",
    "required_keys = {'pregunta', 'respuesta'}\n",
    "if all(key in results[0] for key in required_keys):\n",
    "    print(\"\\nFormato correcto para comparison.ipynb ✓\")\n",
    "else:\n",
    "    print(\"\\nAdvertencia: El formato puede no ser compatible con comparison.ipynb\")\n",
    "    print(f\"Claves esperadas: {required_keys}\")\n",
    "    print(f\"Claves actuales en el primer registro: {set(results[0].keys())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
